{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 479: Machine Learning (Fall 2018)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat479-fs2018/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L11: Model Evaluation 4 -- Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka 2018-11-07 \n",
      "\n",
      "CPython 3.6.7\n",
      "IPython 6.5.0\n",
      "\n",
      "sklearn 0.20.0\n",
      "mlxtend 0.14.0dev\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -d -p sklearn,mlxtend -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.data import mnist_data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading and splitting the dataset\n",
    "# Note that this is a small (stratified) subset\n",
    "# of MNIST; it consists of 5000 samples only, that is,\n",
    "# 10% of the original MNIST dataset\n",
    "# http://yann.lecun.com/exdb/mnist/\n",
    "X, y = mnist_data()\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Initializing Classifiers\n",
    "clf1 = LogisticRegression(multi_class='multinomial',\n",
    "                          solver='newton-cg',\n",
    "                          random_state=1)\n",
    "clf2 = KNeighborsClassifier(algorithm='ball_tree',\n",
    "                            leaf_size=50)\n",
    "clf3 = DecisionTreeClassifier(random_state=1)\n",
    "clf4 = SVC(random_state=1)\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf1', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf2', clf2)])\n",
    "\n",
    "pipe4 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf4', clf4)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'clf1__penalty': ['l2'],\n",
    "                'clf1__C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "param_grid2 = [{'clf2__n_neighbors': list(range(1, 10)),\n",
    "                'clf2__p': [1, 2]}]\n",
    "\n",
    "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],\n",
    "                'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "param_grid4 = [{'clf4__kernel': ['rbf'],\n",
    "                'clf4__C': np.power(10., np.arange(-4, 4)),\n",
    "                'clf4__gamma': np.power(10., np.arange(-5, 0))},\n",
    "               {'clf4__kernel': ['linear'],\n",
    "                'clf4__C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2,\n",
    "                             param_grid3, param_grid4),\n",
    "                            (pipe1, pipe2, clf3, pipe4),\n",
    "                            ('Softmax', 'KNN', 'DTree', 'SVM')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree | outer ACC 77.25% +/- 2.05\n",
      "KNN | outer ACC 91.17% +/- 1.07\n",
      "SVM | outer ACC 91.93% +/- 1.38\n",
      "Softmax | outer ACC 90.25% +/- 1.31\n"
     ]
    }
   ],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train, \n",
    "                                   y=y_train, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=-1)\n",
    "    print('%s | outer ACC %.2f%% +/- %.2f' % \n",
    "          (name, nested_score.mean() * 100, nested_score.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.30% (average over CV test folds)\n",
      "Best Parameters: {'clf4__C': 100.0, 'clf4__gamma': 0.001, 'clf4__kernel': 'rbf'}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n"
     ]
    }
   ],
   "source": [
    "# Fitting a model to the whole training set\n",
    "# using the \"best\" algorithm\n",
    "best_algo = gridcvs['SVM']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['SVM'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
